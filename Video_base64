# ============================================================================
# WAV2LIP DATABRICKS - ISOLATED (No numba/numpy conflicts)
# ============================================================================

import sys
import os
import subprocess
import tempfile

# YOUR PATHS
WAV2LIP_BASE = "/Volumes/lab37_catalog/ifstrolley/trolley/wav2lip/Wav2Lip-master"
MODEL_PATH = "/Volumes/lab37_catalog/ifstrolley/trolley/wav2lip/wav2lip_gan.pth"
INPUT_VIDEO = "/Volumes/lab37_catalog/ifstrolley/trolley/indigo_airhostress_response_v2.mp4"
INPUT_AUDIO = "/Volumes/lab37_catalog/ifstrolley/trolley/audio_file.wav"
OUTPUT_VIDEO = "/Volumes/lab37_catalog/ifstrolley/trolley/REAL_wav2lip_output.mp4"

# üî• CREATE ISOLATED FOLDER (no Databricks conflicts)
temp_dir = f"{WAV2LIP_BASE}_isolated"
os.makedirs(temp_dir, exist_ok=True)

print("üîß ISOLATED ENVIRONMENT...")

# Copy ONLY needed files
for item in ["inference.py", "models", "face_detection", "wav2lip.py"]:
    src = f"{WAV2LIP_BASE}/{item}"
    dst = f"{temp_dir}/{item}"
    if os.path.exists(src):
        if os.path.isdir(src):
            subprocess.run(["cp", "-r", src, temp_dir], check=False)
        else:
            subprocess.run(["cp", src, temp_dir], check=False)

# Copy model
subprocess.run(["cp", MODEL_PATH, f"{temp_dir}/wav2lip_gan.pth"], check=False)

# SIMPLIFIED face_detection (no torch dependency)
detector_path = f"{temp_dir}/face_detection/detector.py"
with open(detector_path, 'w') as f:
    f.write('''
import cv2
import numpy as np

class FaceDetector:
    def __init__(self, device="cpu"):
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    
    def detect_from_batch(self, images):
        bboxes = []
        for img in images:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)
            if len(faces) > 0:
                face = faces[0]
                h, w = img.shape[:2]
                bbox = [max(0, face[0]-20), max(0, face[1]-20), 
                       min(w, face[0]+face[2]+20), min(h, face[1]+face[3]+40)]
                bboxes.append([bbox])
            else:
                h, w = img.shape[:2]
                bboxes.append([[w//4, h//4, 3*w//4, 3*h//4]])  # Center crop
        return bboxes
''')

print("‚úÖ ISOLATED + OpenCV face detection")

# Install ONLY OpenCV (no torch/numba conflicts)
print("üì¶ MINIMAL INSTALL...")
subprocess.run([
    "pip", "install", "-q", 
    "opencv-python-headless==4.8.1.78",
    "librosa==0.9.1",
    "imageio-ffmpeg==0.5.1"
], check=False)

print("\nüé¨ **LAUNCHING ISOLATED WAV2LIP**")
os.chdir(temp_dir)

cmd = [
    "python", "inference.py",
    "--checkpoint_path", "wav2lip_gan.pth",
    "--face", INPUT_VIDEO,
    "--audio", INPUT_AUDIO,
    "--outfile", OUTPUT_VIDEO,
    "--resize_factor", "2"
]

print("Executing:", " ".join(cmd))
result = subprocess.run(cmd, capture_output=True, text=True, timeout=900)

print("\\nüìã RESULTS:")
print("STDOUT:", result.stdout[-400:] if result.stdout else "(empty)")
print("STDERR:", result.stderr[-400:] if result.stderr else "(empty)")
print(f"Code: {result.returncode}")

if os.path.exists(OUTPUT_VIDEO):
    size = os.path.getsize(OUTPUT_VIDEO) / 1e6
    print(f"\\nüéâ **SUCCESS!** üé¨ {OUTPUT_VIDEO} ({size:.1f}MB)")
    print("‚úÖ DOWNLOAD: Catalog ‚Üí trolley ‚Üí REAL_wav2lip_output.mp4")
    print("‚ñ∂Ô∏è  LIPS WILL MOVE WITH AUDIO!")
else:
    print("\\n‚è≥ Check folder in 3-5 minutes...")
