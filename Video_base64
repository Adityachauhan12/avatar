import torch
import cv2
import numpy as np
import librosa
from scipy import signal
import dlib
from pathlib import Path
from tqdm import tqdm

class VideoPreprocessor:
    """Preprocess video and extract faces/audio"""
    
    def __init__(self, checkpoint_dir):
        self.checkpoint_dir = checkpoint_dir
        self.face_det_checkpoint = os.path.join(checkpoint_dir, "mmod_human_face_detector.dat")
        
        # Try to load dlib face detector
        try:
            import dlib
            self.face_detector = dlib.cnn_face_detection_model_v1(self.face_det_checkpoint)
            print("âœ… dlib face detector loaded")
        except:
            print("âš ï¸ dlib detector not available, will use MediaPipe")
            try:
                import mediapipe as mp
                self.face_detector = None
                self.mp_face_detection = mp.solutions.face_detection.FaceDetection()
                print("âœ… MediaPipe face detector loaded")
            except:
                print("âŒ No face detector available")
                self.face_detector = None
    
    def extract_audio(self, video_path, sample_rate=16000):
        """Extract audio from video"""
        print(f"ðŸ”Š Extracting audio from {video_path}...")
        
        try:
            # Use ffmpeg to extract audio
            audio_path = video_path.replace('.mp4', '_audio.wav')
            cmd = f"ffmpeg -i '{video_path}' -q:a 9 -n '{audio_path}' -loglevel error"
            os.system(cmd)
            
            # Load with librosa
            wav, sr = librosa.load(audio_path, sr=sample_rate)
            print(f"âœ… Audio extracted: {len(wav)/sample_rate:.1f}s @ {sr}Hz")
            
            return wav, sr, audio_path
        except Exception as e:
            print(f"âŒ Audio extraction failed: {e}")
            return None, None, None
    
    def get_mel_spectrogram(self, audio, sample_rate=16000):
        """Convert audio to mel-spectrogram"""
        mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate)
        
        # Normalize
        mel = np.log(np.clip(mel, 1e-9, None))
        
        return mel
    
    def extract_frames(self, video_path, fps=25, face_padding=10):
        """Extract frames from video"""
        print(f"ðŸŽ¬ Extracting frames from {video_path}...")
        
        cap = cv2.VideoCapture(video_path)
        fps_video = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        frames = []
        face_boxes = []
        
        for frame_idx in tqdm(range(total_frames)):
            ret, frame = cap.read()
            if not ret:
                break
            
            # Detect face
            try:
                face_box = self._detect_face(frame)
                if face_box is not None:
                    frames.append(frame)
                    face_boxes.append(face_box)
            except:
                pass
        
        cap.release()
        
        print(f"âœ… Extracted {len(frames)} frames with detected faces")
        return frames, face_boxes, fps_video
    
    def _detect_face(self, frame):
        """Detect face in frame (dlib)"""
        if self.face_detector is None:
            return None
        
        try:
            dets = self.face_detector(frame, 1)
            if len(dets) > 0:
                det = dets
                x1 = det.rect.left()
                y1 = det.rect.top()
                x2 = det.rect.right()
                y2 = det.rect.bottom()
                return (x1, y1, x2, y2)
        except:
            pass
        
        return None




ImportError: libnvJitLink.so.12: cannot open shared object file: No such file or directory
# Initialize preprocessor
preprocessor = VideoPreprocessor(CHECKPOINT_DIR)
print("âœ… Preprocessor ready!")

