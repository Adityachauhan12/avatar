# ============================================================================
# CELL 9: RE-REGISTER MODEL WITH TENSORRT PATCH APPLIED
# ============================================================================
# This cell will:
# 1. Apply the TensorRT version mismatch patch to tensorrt_utils.py
# 2. Re-register the model as Version 20
# 3. Update your serving endpoint
# ============================================================================

import subprocess
import sys
import shutil
import os
import tempfile
import yaml
import git
from pathlib import Path

print("üîß CELL 9: Re-register Model with TensorRT Patch")
print("=" * 60)

# ============================================================================
# STEP 1: Install PyYAML
# ============================================================================
print("\nüì¶ Installing PyYAML...")
subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "pyyaml"])

import mlflow
from mlflow.models.signature import infer_signature
import pandas as pd

# ============================================================================
# STEP 2: Setup MLflow
# ============================================================================
print("üîó Configuring MLflow...")
mlflow.set_registry_uri("databricks-uc")
mlflow.set_experiment("/Shared/ditto_experiment")

# ============================================================================
# STEP 3: DEFINE MODEL SIGNATURE (same as CELL 5)
# ============================================================================
print("üìã Defining model signature...")
test_input = pd.DataFrame({
    "audio_b64": ["UklGRigAAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQAAAAA="],
    "image_b64": ["iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII="]
})

test_output = pd.DataFrame({
    "status": ["success"],
    "message": ["Video generated"],
    "video_b64": ["AAAAIGZ0eXBpc29tAAACAgAAAABpc29tcGF2YzFtcDQyAAAAAAA..."]
})

signature = infer_signature(test_input, test_output)

# ============================================================================
# STEP 4: CREATE CONDA ENVIRONMENT YAML
# ============================================================================
print("üêç Creating conda environment...")

conda_env = {
    "name": "ditto-env",
    "channels": ["conda-forge", "defaults"],
    "dependencies": [
        "python=3.10",
        "pip",
        {
            "pip": [
                "--extra-index-url https://pypi.nvidia.com",
                "torch==2.1.2",
                "torchvision==0.16.2",
                "torchaudio==2.1.2",
                "tensorrt==9.3.0.post12.dev1",
                "tensorrt-libs==9.3.0.post12.dev1",
                "tensorrt-bindings==9.3.0.post12.dev1",
                "cuda-python==12.2.0",
                "onnxruntime-gpu==1.16.3",
                "numpy==1.26.4",
                "gitpython==3.1.40",
                "librosa>=0.10.1",
                "imageio-ffmpeg",
                "opencv-python-headless",
                "soundfile",
                "soxr",
                "imageio",
                "moviepy",
                "mediapipe>=0.10.9",
                "ml_dtypes==0.4.0",
                "einops",
                "omegaconf",
                "huggingface_hub",
                "filetype",
                "tqdm",
                "scikit-image",
                "colored",
                "polygraphy",
                "mlflow==3.8.1"
            ]
        }
    ]
}

conda_file = tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False)
yaml.dump(conda_env, conda_file)
conda_file.close()
conda_file_path = conda_file.name

print(f"‚úÖ Conda environment created: {conda_file_path}")

# ============================================================================
# STEP 5: PREPARE REPO WITH PATCH APPLIED
# ============================================================================
print("\nüîß Preparing repository with TensorRT patch...")

repo_dir = "/tmp/ditto-model-artifact-patched"

# Clean if exists
if os.path.exists(repo_dir):
    shutil.rmtree(repo_dir)
os.makedirs(repo_dir, exist_ok=True)

# Clone repo
print("   ‚è≥ Cloning Ditto repo...")
git.Repo.clone_from(
    "https://github.com/antgroup/ditto-talkinghead.git",
    repo_dir,
    depth=1
)
print("   ‚úÖ Repo cloned")

# Apply np.atan2 patch
print("   ‚è≥ Applying np.atan2 ‚Üí np.arctan2 patch...")
patch_file = os.path.join(repo_dir, "core/aux_models/mediapipe_landmark478.py")
with open(patch_file, "r") as f:
    content = f.read()
if "np.atan2" in content:
    with open(patch_file, "w") as f:
        f.write(content.replace("np.atan2", "np.arctan2"))
    print("   ‚úÖ np.atan2 patch applied")

# Download config from HuggingFace
print("   ‚è≥ Downloading config from HuggingFace Hub...")
from huggingface_hub import snapshot_download

checkpoint_dir = os.path.join(repo_dir, "checkpoints")
os.makedirs(checkpoint_dir, exist_ok=True)
snapshot_download(
    repo_id="digital-avatar/ditto-talkinghead",
    local_dir=checkpoint_dir,
    allow_patterns=["ditto_cfg/*"],
    cache_dir=checkpoint_dir
)
print("   ‚úÖ Config downloaded")

# ============================================================================
# STEP 6: APPLY TENSORRT VERSION MISMATCH PATCH
# ============================================================================
print("\nüîß Applying TensorRT version mismatch patch...")

tensorrt_utils_path = os.path.join(repo_dir, "core/utils/tensorrt_utils.py")

# Backup original
shutil.copy(tensorrt_utils_path, tensorrt_utils_path + ".backup_v2")
print(f"   üì¶ Backup created: {tensorrt_utils_path}.backup_v2")

# Read current file
with open(tensorrt_utils_path, "r") as f:
    content = f.read()

# THE PATCH: Replace simple assert with try-except handling
old_pattern = """ self.engine = runtime.deserialize_cuda_engine(f.read())
            assert self.engine"""

new_pattern = """ self.engine = runtime.deserialize_cuda_engine(f.read())
            except Exception as e:
                if "Version tag does not match" in str(e) or "Serialization" in str(e):
                    print(f"‚ö†Ô∏è TensorRT engine format mismatch detected!")
                    print(f"   Expected: TensorRT 8.6.1 or compatible")
                    print(f"   Engine built with: TensorRT 9.6+ (version mismatch)")
                    self.engine = None
                else:
                    raise
            
            assert self.engine, f"Failed to load engine. Rebuild required with matching TensorRT version."""

if old_pattern in content:
    content = content.replace(old_pattern, new_pattern)
    with open(tensorrt_utils_path, "w") as f:
        f.write(content)
    print("   ‚úÖ TensorRT patch applied successfully")
else:
    print("   ‚ö†Ô∏è  WARNING: Could not find exact pattern to patch")
    print("   Manual inspection may be needed, but proceeding anyway...")

# ============================================================================
# STEP 7: COPY TENSORRT ENGINES
# ============================================================================
print("\nüìã Copying TensorRT engines to model artifact...")

dbfs_checkpoint = "/dbfs/FileStore/ditto_checkpoints/ditto_trt_t4"
local_checkpoint = os.path.join(repo_dir, "checkpoints", "ditto_trt_t4")
os.makedirs(local_checkpoint, exist_ok=True)

if os.path.exists(dbfs_checkpoint):
    engine_count = 0
    for file in os.listdir(dbfs_checkpoint):
        src = os.path.join(dbfs_checkpoint, file)
        dst = os.path.join(local_checkpoint, file)
        if os.path.isfile(src):
            shutil.copy2(src, dst)
            engine_count += 1
            print(f"   ‚úÖ {file}")
    print(f"   Total engines copied: {engine_count}")
else:
    print(f"   ‚ö†Ô∏è  WARNING: DBFS checkpoint path not found: {dbfs_checkpoint}")
    print("   Continuing without engine files (will fail at runtime with clear error)")

# ============================================================================
# STEP 8: LOG MODEL WITH PATCHED CODE
# ============================================================================
print("\nüìù Logging model with patched code...")

with mlflow.start_run() as run:
    mlflow.pyfunc.log_model(
        artifact_path="ditto_talking_head_v2",
        python_model=DittoTalkingHeadModel(),
        signature=signature,
        conda_env=conda_file_path,
        artifacts={"repo": repo_dir}
    )
    run_id = run.info.run_id

print(f"‚úÖ Model logged with run ID: {run_id}")

# ============================================================================
# STEP 9: REGISTER MODEL AS VERSION 20
# ============================================================================
print("\nüöÄ Registering as new model version...")

uc_model_name = "lab37_catalog.ifstrolley.ditto_talkinghead"

try:
    model_version = mlflow.register_model(
        model_uri=f"runs:/{run_id}/ditto_talking_head_v2",
        name=uc_model_name
    )
    version_number = model_version.version
    print(f"‚úÖ SUCCESS! Registered Version: {version_number}")
    print(f"\nüéØ Next Steps:")
    print(f"   1. Go to Serving ‚Üí ditto_base64_v10 (or your endpoint name)")
    print(f"   2. Click 'Update'")
    print(f"   3. Select Version {version_number}")
    print(f"   4. Click 'Deploy'")
    print(f"   5. Wait for READY status")
    print(f"   6. Run the test cell again to see clear error message")
except Exception as e:
    print(f"‚ùå Error registering model: {e}")
    print(f"   This might be expected if running for first time")

# ============================================================================
# STEP 10: CLEANUP
# ============================================================================
print("\nüßπ Cleaning up temporary files...")
try:
    os.unlink(conda_file_path)
    print("‚úÖ Cleanup complete")
except:
    pass

print("\n" + "=" * 60)
print("‚úÖ CELL 9 COMPLETE!")
print("=" * 60)
print("\nüìå IMPORTANT: You need to manually update the serving endpoint!")
print("   Go to Databricks UI ‚Üí Serving ‚Üí ditto_base64_v10")
print("   Update to the new version and restart")
print("\nüéØ After updating endpoint, run this test cell to verify the patch:")
print("""
import requests, base64, json

endpoint_url = "https://adb-7012066134936526.6.azuredatabricks.net/serving-endpoints/ditto_base64_v10/invocations"
token = ""  # your token

audio_path = "/Volumes/lab37_catalog/ifstrolley/trolley/Thank you for bookin (1).wav"
image_path = "/Volumes/lab37_catalog/ifstrolley/trolley/new.png"

with open(audio_path, "rb") as f:
    audio_b64 = base64.b64encode(f.read()).decode("utf-8")

with open(image_path, "rb") as f:
    image_b64 = base64.b64encode(f.read()).decode("utf-8")

payload = {
    "dataframe_split": {
        "columns": ["audio_b64", "image_b64"],
        "data": [[audio_b64, image_b64]],
    }
}

headers = {
    "Authorization": f"Bearer {token}",
    "Content-Type": "application/json",
}

resp = requests.post(endpoint_url, json=payload, headers=headers)
print(f"Status: {resp.status_code}")
print(json.dumps(resp.json(), indent=2)[:3000])

# Expected output:
# ‚ö†Ô∏è TensorRT engine format mismatch detected!
#    Expected: TensorRT 8.6.1 or compatible
#    Engine built with: TensorRT 9.6+ (version mismatch)
""")
