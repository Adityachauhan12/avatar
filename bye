import os
import sys

musetalk_root = "/dbfs/FileStore/MuseTalk"
script_path = f"{musetalk_root}/scripts/inference_final_v4.py"

# Read original code
with open(f"{musetalk_root}/scripts/inference.py", "r") as f:
    original_code = f.read()

# Define the "All-in-One" Header with OPENMMLAB SUPPORT
all_in_one_header = """
import sys
import os
import subprocess

# --- 1. DISABLE BROKEN FLASH ATTENTION ---
sys.modules["flash_attn"] = None
# -----------------------------------------

# --- 2. SELF-INSTALL COMPATIBLE DEPENDENCIES ---
def install_if_missing(package, pip_name=None, extra_args=None):
    if pip_name is None: pip_name = package
    try:
        __import__(package)
    except ImportError:
        print(f"üì¶ Installing missing: {pip_name}...")
        try:
            cmd = [sys.executable, "-m", "pip", "install", pip_name]
            if extra_args:
                cmd.extend(extra_args)
            subprocess.check_call(cmd)
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to install {pip_name}: {e}")

# CRITICAL VERSIONS FOR TESLA T4 + PYTORCH 2.0.1
install_if_missing("diffusers", "diffusers==0.27.2")     
install_if_missing("transformers", "transformers==4.39.2")
install_if_missing("accelerate", "accelerate==0.28.0")
install_if_missing("omegaconf", "omegaconf==2.3.0")
install_if_missing("tensorboardX", "tensorboardX")
install_if_missing("ffmpeg", "ffmpeg-python")
install_if_missing("lpips", "lpips")
install_if_missing("facexlib", "facexlib")

# --- INSTALL OPENMMLAB (MMPose, MMDet, MMCV) ---
# We use the specific URL for CUDA 11.8 + PyTorch 2.0
mmlab_url = "https://download.openmmlab.com/mmcv/dist/cu118/torch2.0/index.html"

# Order matters: MMCV first, then Det, then Pose
install_if_missing("mmcv", "mmcv==2.0.1", ["-f", mmlab_url])
install_if_missing("mmdet", "mmdet==3.1.0", ["-f", mmlab_url])
install_if_missing("mmpose", "mmpose==1.1.0", ["-f", mmlab_url])

# --- 3. MONKEY PATCH PYTORCH ---
import torch
if not hasattr(torch.library, 'impl_abstract'):
    def impl_abstract(qualname, func=None, *, lib=None, _stacklevel=1):
        def decorator(f): return f
        if func is not None: return decorator(func)
        return decorator
    torch.library.impl_abstract = impl_abstract

sys.path.append(os.getcwd())
"""

# Save the new script
with open(script_path, "w") as f:
    f.write(all_in_one_header + original_code)

print(f"‚úì Created self-healing script v4: {script_path}")

# Run it
import subprocess

cmd = [
    sys.executable, "-m", "scripts.inference_final_v4",
    "--inference_config", f"{musetalk_root}/configs/inference/my_inference.yaml",
    "--result_dir", "/Volumes/lab37_catalog/ifstrolley/trolley/musetalk_output",
    "--unet_model_path", "./models/musetalk/pytorch_model.bin",
    "--unet_config", "./models/musetalk/musetalk.json",
    "--use_float16" 
]

os.chdir(musetalk_root)
print(f"üöÄ Starting MuseTalk (Self-Healing V4: OpenMMLab Fix)...")
print("   This may take a minute to install mmpose/mmcv if missing.")

process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
for line in process.stdout:
    print(line, end="")

process.wait()

if process.returncode == 0:
    print(f"\n‚úÖ SUCCESS!")
else:
    print(f"\n‚ùå FAILED")
