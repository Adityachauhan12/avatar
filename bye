from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
import requests
import base64
import os
from pathlib import Path
from dotenv import load_dotenv
import uuid

load_dotenv()

app = FastAPI()

# Configuration
DATABRICKS_HOST = os.getenv("DATABRICKS_HOST")
DATABRICKS_TOKEN = os.getenv("DATABRICKS_TOKEN")
SARVAM_API_KEY = os.getenv("SARVAM_API_KEY")
ENDPOINT_NAME = os.getenv("ENDPOINT_NAME")
UPLOADS_DIR = Path("uploads")
UPLOADS_DIR.mkdir(exist_ok=True)
SARVAM_TRANSLATE_URL = os.getenv("SARVAM_TRANSLATE_URL", "https://api.sarvam.ai/translate")
SARVAM_TTS_URL = os.getenv("SARVAM_TTS_URL", "https://api.sarvam.ai/text-to-speech")

# Language & Voice Configuration
LANGUAGES = {
    "en-IN": {"name": "English", "native_name": "English"},
    "hi-IN": {"name": "Hindi", "native_name": "‡§π‡§ø‡§Ç‡§¶‡•Ä"},
    "ta-IN": {"name": "Tamil", "native_name": "‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç"},
    "te-IN": {"name": "Telugu", "native_name": "‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å"},
    "ml-IN": {"name": "Malayalam", "native_name": "‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç"},
    "kn-IN": {"name": "Kannada", "native_name": "‡≤ï‡≤®‡≥ç‡≤®‡≤°"},
    "mr-IN": {"name": "Marathi", "native_name": "‡§Æ‡§∞‡§æ‡§†‡•Ä"},
    "gu-IN": {"name": "Gujarati", "native_name": "‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä"},
    "bn-IN": {"name": "Bengali", "native_name": "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ"},
    "pa-IN": {"name": "Punjabi", "native_name": "‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä"},
    "od-IN": {"name": "Odia", "native_name": "‡¨ì‡¨°‡¨º‡¨ø‡¨Ü"},
}

VOICES = {
    "hi-IN": ["shubh", "ritu", "rahul", "pooja", "simran", "kavya", "ratan", "rohan"],
    "en-IN": ["shubh", "ritu", "rahul", "pooja", "amelia", "sophia"],
    "ta-IN": ["shubh", "ritu", "rahul", "pooja"],
    "te-IN": ["shubh", "ritu", "rahul", "pooja"],
    "ml-IN": ["shubh", "ritu", "rahul", "pooja"],
    "kn-IN": ["shubh", "ritu", "rahul", "pooja"],
    "mr-IN": ["shubh", "ritu", "rahul", "pooja"],
    "gu-IN": ["shubh", "ritu", "rahul", "pooja"],
    "bn-IN": ["shubh", "ritu", "rahul", "pooja"],
    "pa-IN": ["shubh", "ritu", "rahul", "pooja"],
    "od-IN": ["shubh", "ritu", "rahul", "pooja"],
}

# ============ STEP 1: TRANSLATE TEXT (SARVAM TRANSLATION API) ============
def translate_text(text: str, source_lang: str, target_lang: str) -> str:
    """
    Translate text from source language to target language using Sarvam API
    Source language is always English (en-IN)
    Returns: Translated text
    """
    if source_lang == target_lang:
        return text
    
    url = SARVAM_TRANSLATE_URL
    
    headers = {
        "api-subscription-key": SARVAM_API_KEY,
        "Content-Type": "application/json"
    }
    
    payload = {
        "input": text,
        "source_language_code": source_lang,
        "target_language_code": target_lang,
        "speaker_gender": "Male",
        "mode": "formal",
        "model": "mayura:v1",
        "enable_preprocessing": True,
    }
    
    try:
        response = requests.post(url, json=payload, headers=headers, timeout=30)
        response.raise_for_status()
        
        result = response.json()
        if 'translated_text' in result:
            return result['translated_text']
        else:
            raise HTTPException(status_code=500, detail="Translation API returned unexpected format")
    
    except requests.exceptions.HTTPError as e:
        error_detail = f"Translation API error: {e.response.status_code} - {e.response.text}"
        raise HTTPException(status_code=500, detail=error_detail)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Translation error: {str(e)}")

# ============ STEP 2: TEXT TO AUDIO (SARVAM API) ============
def text_to_audio(text: str, language: str, speaker: str) -> bytes:
    """
    Convert text to audio using Sarvam API v3
    Returns: Audio bytes (MP3 format)
    """
    url = SARVAM_TTS_URL
    
    headers = {
        "API-Subscription-Key": SARVAM_API_KEY,
        "Content-Type": "application/json"
    }
    
    # Split text into chunks of 2500 chars
    max_chars = 2500
    chunks = [text[i:i+max_chars] for i in range(0, len(text), max_chars)]
    
    all_audio_bytes = b''
    
    for chunk in chunks:
        payload = {
            "text": chunk,
            "target_language_code": language,
            "speaker": speaker,
            "pace": 1.0,
            "speech_sample_rate": 8000,
            "enable_preprocessing": True,
            "model": "bulbul:v3-beta",
            "output_audio_codec": "mp3"
        }
        
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            response.raise_for_status()
            
            audio_data = response.json()
            if 'audios' in audio_data and len(audio_data['audios']) > 0:
                audio_bytes = base64.b64decode(audio_data['audios'][0])
                all_audio_bytes += audio_bytes
            else:
                raise HTTPException(status_code=500, detail="Text-to-Speech API returned no audio")
        
        except requests.exceptions.HTTPError as e:
            error_detail = f"Text-to-Speech API error: {e.response.status_code} - {e.response.text}"
            raise HTTPException(status_code=500, detail=error_detail)
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Text-to-Speech error: {str(e)}")
    
    return all_audio_bytes

# ============ STEP 3: FILE TO BASE64 ============
def file_to_base64(file_bytes: bytes) -> str:
    """Convert file bytes to base64 string"""
    return base64.b64encode(file_bytes).decode('utf-8')

# ============ STEP 4: SEND TO DATABRICKS ENDPOINT ============
def call_databricks_endpoint(image_b64: str, audio_b64: str) -> str:
    """
    Send image and audio base64 to Databricks endpoint
    Returns: Video base64 response
    """
    url = f"{DATABRICKS_HOST}/serving-endpoints/{ENDPOINT_NAME}/invocations"
    
    headers = {
        "Authorization": f"Bearer {DATABRICKS_TOKEN}",
        "Content-Type": "application/json"
    }
    
    # Format matches your curl command
    payload = {
        "dataframe_split": {
            "columns": ["audio_b64", "image_b64"],
            "data": [[audio_b64, image_b64]]
        }
    }
    
    try:
        response = requests.post(url, json=payload, headers=headers, timeout=300)
        response.raise_for_status()
        
        result = response.json()
        
        # Extract video base64 from response
        if 'predictions' in result:
            predictions = result['predictions']
            # Check for error status
            if isinstance(predictions, dict):
                if predictions.get('status') == 'error':
                    error_msg = predictions.get('message', 'Unknown error from endpoint')
                    raise HTTPException(status_code=500, detail=f"Endpoint error: {error_msg}")
                elif 'video_b64' in predictions:
                    return predictions['video_b64']
            # Handle list format (fallback)
            elif isinstance(predictions, list) and len(predictions) > 0:
                return predictions[0]
        
        raise HTTPException(status_code=500, detail=f"Unexpected response format from endpoint: {result}")
    
    except requests.exceptions.RequestException as e:
        raise HTTPException(status_code=500, detail=f"Databricks endpoint error: {str(e)}")

# ============ STEP 5: BASE64 TO VIDEO FILE ============
def base64_to_video_file(video_b64: str, filename: str) -> Path:
    """
    Convert base64 to video file and save
    Returns: Path to saved video file
    """
    try:
        video_bytes = base64.b64decode(video_b64)
        file_path = UPLOADS_DIR / filename
        
        with open(file_path, 'wb') as f:
            f.write(video_bytes)
        
        return file_path
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error saving video: {str(e)}")

# ============ API ENDPOINTS ============

@app.get("/api/languages")
async def get_languages():
    """Get all supported languages and voices"""
    return {
        "languages": LANGUAGES,
        "voices": VOICES
    }

@app.get("/api/voices/{language}")
async def get_voices_for_language(language: str):
    """Get available voices for a specific language"""
    if language not in VOICES:
        raise HTTPException(status_code=400, detail=f"Language {language} not supported")
    
    return {
        "language": language,
        "voices": VOICES[language]
    }

@app.post("/api/generate-avatar")
async def generate_avatar(
    text: str,
    language: str,
    speaker: str,
    image: UploadFile = File(...)
):
    """
    Main endpoint: Accepts text + image + language + speaker, returns video
    
    Flow:
    1. Translate English text to target language
    2. Convert translated text to audio in target language
    3. Send image + audio to Databricks endpoint
    4. Get video back and save it
    """
    try:
        # Validate language and speaker
        if language not in LANGUAGES:
            raise HTTPException(status_code=400, detail=f"Language {language} not supported")
        
        if language not in VOICES or speaker not in VOICES[language]:
            raise HTTPException(status_code=400, detail=f"Speaker {speaker} not supported for {language}")
        
        # Read image file
        image_bytes = await image.read()
        image_b64 = file_to_base64(image_bytes)
        
        print(f"üîÑ Step 1: Translating text from en-IN to {language}...")
        # Step 1: Translate text to target language
        translated_text = translate_text(text, "en-IN", language)
        print(f"‚úÖ Translated text: {translated_text}")
        
        print(f"üîÑ Step 2: Converting translated text to audio ({speaker} voice)...")
        # Step 2: Convert translated text to audio
        audio_bytes = text_to_audio(translated_text, language, speaker)
        audio_b64 = file_to_base64(audio_bytes)
        print(f"‚úÖ Audio generated successfully")
        
        print(f"üîÑ Step 3: Sending to Databricks endpoint...")
        # Step 3: Call Databricks endpoint
        video_b64 = call_databricks_endpoint(image_b64, audio_b64)
        print(f"‚úÖ Video received from endpoint (length: {len(video_b64)} chars)")
        
        # Debug: Check if video has audio by examining first bytes after decode
        try:
            video_test = base64.b64decode(video_b64[:100])
            print(f"üîç Video header (first 50 bytes): {video_test[:50]}")
        except:
            pass
        
        print(f"üîÑ Step 4: Saving video...")
        # Step 4: Save video to file
        unique_id = str(uuid.uuid4())[:8]
        video_filename = f"avatar_{unique_id}.mp4"
        video_path = base64_to_video_file(video_b64, video_filename)
        print(f"‚úÖ Video saved: {video_filename}")
        
        return {
            "status": "success",
            "message": "Avatar generated successfully",
            "video_url": f"/api/download-video/{video_filename}",
            "filename": video_filename,
            "language": language,
            "speaker": speaker,
            "original_text": text,
            "translated_text": translated_text
        }
    
    except HTTPException as e:
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error: {str(e)}")

@app.get("/api/download-video/{filename}")
async def download_video(filename: str):
    """Download generated video"""
    file_path = UPLOADS_DIR / filename
    
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="Video not found")
    
    return FileResponse(
        file_path,
        media_type="video/mp4",
        filename=filename
    )

@app.get("/api/health")
async def health_check():
    return {"status": "healthy"}

# Serve static frontend files (must be last)
STATIC_DIR = Path("static")
if STATIC_DIR.exists():
    app.mount("/", StaticFiles(directory="static", html=True), name="static")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
