# CELL 5 - COPY CHECKPOINTS TO MODEL ARTIFACT BEFORE LOGGING

import subprocess
import sys
import shutil
import os

print("üì¶ Installing PyYAML...")
subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "pyyaml"])

import mlflow
from mlflow.models.signature import infer_signature
import pandas as pd
import yaml
import tempfile
import git

mlflow.set_registry_uri("databricks-uc")
mlflow.set_experiment("/Shared/ditto_experiment")

# Define Signature
test_input = pd.DataFrame({
    "audio_b64": ["UklGRigAAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQAAAAA="],
    "image_b64": ["iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII="]
})

test_output = pd.DataFrame({
    "status": ["success"],
    "message": ["Video generated"],
    "video_b64": ["AAAAIGZ0eXBpc29tAAACAgAAAABpc29tcGF2YzFtcDQyAAAAAAA..."]
})

signature = infer_signature(test_input, test_output)

print("üì¶ Creating conda.yaml with PyTorch...")

# CREATE CONDA ENV - WITH PYTORCH
conda_env = {
    "name": "ditto-env",
    "channels": ["conda-forge", "defaults"],
    "dependencies": [
        "python=3.10",
        "pip",
        {
            "pip": [
                "--extra-index-url https://pypi.nvidia.com",
                # PyTorch (MUST come before TensorRT)
                "torch==2.1.2",
                "torchvision==0.16.2",
                "torchaudio==2.1.2",
                # TensorRT
                "tensorrt==9.3.0.post12.dev1",
                "cuda-python==12.2.0",
                "onnxruntime-gpu==1.16.3",
                "numpy==1.26.4",
                "gitpython==3.1.40",
                "librosa>=0.10.1",
                "imageio-ffmpeg",
                "opencv-python-headless",
                "soundfile",
                "soxr",
                "imageio",
                "moviepy",
                "mediapipe>=0.10.9",
                "ml_dtypes==0.4.0",
                "einops",
                "omegaconf",
                "huggingface_hub",
                "filetype",
                "tqdm",
                "scikit-image",
                "colored",
                "polygraphy",
                "mlflow==3.8.1"
            ]
        }
    ]
}

conda_file = tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False)
yaml.dump(conda_env, conda_file)
conda_file.close()
conda_file_path = conda_file.name

print(f"‚úÖ Conda environment created")

# ‚úÖ SETUP REPO WITH CHECKPOINTS
print("üîÑ Preparing repo with checkpoints...")
repo_dir = "/tmp/ditto-model-artifact"
if os.path.exists(repo_dir):
    shutil.rmtree(repo_dir)
os.makedirs(repo_dir, exist_ok=True)

# Clone repo
print("   Cloning repo...")
git.Repo.clone_from(
    "https://github.com/antgroup/ditto-talkinghead.git",
    repo_dir,
    depth=1
)

# Apply patch
print("   Applying np.atan2 patch...")
patch_file = os.path.join(repo_dir, "core/aux_models/mediapipe_landmark478.py")
with open(patch_file, "r") as f:
    content = f.read()
if "np.atan2" in content:
    with open(patch_file, "w") as f:
        f.write(content.replace("np.atan2", "np.arctan2"))

# Download config from HF
print("   Downloading config from HuggingFace...")
from huggingface_hub import snapshot_download
checkpoint_dir = os.path.join(repo_dir, "checkpoints")
os.makedirs(checkpoint_dir, exist_ok=True)
snapshot_download(
    repo_id="digital-avatar/ditto-talkinghead",
    local_dir=checkpoint_dir,
    allow_patterns=["ditto_cfg/*"],
    cache_dir=checkpoint_dir
)

# ‚úÖ COPY TensorRT engines to repo
print("   Copying TensorRT engines...")
dbfs_checkpoint = "/dbfs/FileStore/ditto_checkpoints/ditto_trt_t4"
local_checkpoint = os.path.join(repo_dir, "checkpoints", "ditto_trt_t4")
os.makedirs(local_checkpoint, exist_ok=True)

for file in os.listdir(dbfs_checkpoint):
    src = os.path.join(dbfs_checkpoint, file)
    dst = os.path.join(local_checkpoint, file)
    if os.path.isfile(src):
        print(f"      Copying {file}...")
        shutil.copy2(src, dst)

print("‚úÖ Repo prepared with all checkpoints")

# Log with artifacts
print("üìù Logging model with artifacts...")
with mlflow.start_run() as run:
    mlflow.pyfunc.log_model(
        artifact_path="ditto_talking_head",
        python_model=DittoTalkingHeadModel(),
        signature=signature,
        conda_env=conda_file_path,
        pip_requirements=None,
        artifacts={"repo": repo_dir}  # ‚úÖ INCLUDE REPO AS ARTIFACT
    )
    run_id = run.info.run_id

print(f"‚úÖ Model Logged with artifacts. Run ID: {run_id}")

uc_model_name = "lab37_catalog.ifstrolley.ditto_talkinghead"

try:
    model_version = mlflow.register_model(
        model_uri=f"runs:/{run_id}/ditto_talking_head",
        name=uc_model_name
    )
    print(f"‚úÖ SUCCESS! Registered Version: {model_version.version}")
    print(f"üëâ Go to Serving ‚Üí ditto_with_base64 ‚Üí Update to Version {model_version.version}")
except Exception as e:
    print(f"‚ùå Error: {e}")

try:
    os.unlink(conda_file_path)
except:
    pass
